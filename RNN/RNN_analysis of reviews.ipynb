{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"homework1.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iWaRbYIMBn9M","outputId":"2504d719-7a4f-4bf5-de7d-6eae111dc7e9"},"source":["'''\n","3주차 RNN 영화 리뷰 감정 분석 실습 코드입니다.\n","rnn을 gru, lstm으로 자유롭게 변경해보고, 결과를 비교해 보세요.\n","'''\n","import os\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torchtext import data, datasets\n","\n","\n","# 하이퍼파라미터 정의\n","BATCH_SIZE = 64\n","lr = 0.001\n","EPOCHS = 20\n","USE_CUDA = torch.cuda.is_available()\n","DEVICE = torch.device(\"cuda\" if USE_CUDA else \"cpu\")\n","print(\"다음 기기로 학습합니다:\", DEVICE)\n","## colab GPU 사용 방법 --> 상단 메뉴에서 \"런타임\"클릭, \"런타임 유형 변경\"클릭, 하드웨어 가속기를 \"GPU\"로 변경 ##\n","\n","# 데이터 로딩하기\n","print(\"데이터 로딩중...\")\n","TEXT = data.Field(sequential=True, batch_first=True, lower=True)\n","LABEL = data.Field(sequential=False, batch_first=True)\n","trainset, testset = datasets.IMDB.splits(TEXT, LABEL)\n","TEXT.build_vocab(trainset, min_freq=5)\n","LABEL.build_vocab(trainset)\n","\n","# 학습용 데이터를 학습셋 80% 검증셋 20% 로 나누기\n","trainset, valset = trainset.split(split_ratio=0.8)\n","train_iter, val_iter, test_iter = data.BucketIterator.splits(\n","        (trainset, valset, testset), batch_size=BATCH_SIZE,\n","        shuffle=True, repeat=False)\n","# 아래의 코드로 데이터를 직접 확인해 보세요.\n","#print(vars(trainset[0]))\n","\n","vocab_size = len(TEXT.vocab)\n","n_classes = 2\n","\n","print(\"[학습 데이터]: %d [검증 데이터]: %d [테스트 데이터]: %d [단어수]: %d [클래스] %d\"\n","      % (len(trainset),len(valset), len(testset), vocab_size, n_classes))\n","\n","class RNN(nn.Module):\n","    def __init__(self, n_layers, hidden_dim, n_vocab, embed_dim, n_classes, dropout_p=0.2):\n","        super(RNN, self).__init__()\n","        print(\"Building Basic RNN model...\") # 각각 RNN, LSTM, GRU로 수정하여 출력하기\n","        self.n_layers = n_layers\n","        self.embed = nn.Embedding(n_vocab, embed_dim)\n","        self.hidden_dim = hidden_dim\n","        self.dropout = nn.Dropout(dropout_p)\n","        ## self.rnn을 RNN, GRU, LSTM으로 변경해 줄 수 있습니다.\n","        ## 함수 사용 방법은 아래 링크를 참고해주세요\n","        ## GRU : https://pytorch.org/docs/stable/generated/torch.nn.GRU.html\n","        ## LSTM : https://pytorch.org/docs/stable/generated/torch.nn.LSTM.html\n","        self.rnn = nn.RNN(embed_dim, self.hidden_dim,\n","                          num_layers=self.n_layers,\n","                          batch_first=True)\n","        self.out = nn.Linear(self.hidden_dim, n_classes)\n","\n","    def forward(self, x):\n","        x = self.embed(x)\n","        h_0 = self._init_state(batch_size=x.size(0))\n","        x, _status = self.rnn(x, h_0)  # [i, b, h]\n","\n","        # 예측을 위해 마지막 output만을 사용\n","        h_t = x[:,-1,:]\n","        self.dropout(h_t)\n","        logit = self.out(h_t)  # [b, h] -> [b, o]\n","        return logit\n","    \n","    def _init_state(self, batch_size=1):\n","        weight = next(self.parameters()).data\n","        return weight.new(self.n_layers, batch_size, self.hidden_dim).zero_()\n","\n","def train(model, optimizer, train_iter):\n","    model.train()\n","    for b, batch in enumerate(train_iter):\n","        x, y = batch.text.to(DEVICE), batch.label.to(DEVICE)\n","        y.data.sub_(1)  # 레이블 값을 0과 1로 변환\n","        optimizer.zero_grad()\n","        logit = model(x)\n","        loss = F.cross_entropy(logit, y)\n","        loss.backward()\n","        optimizer.step()\n","\n","def evaluate(model, val_iter):\n","    \"\"\"evaluate model\"\"\"\n","    model.eval()\n","    corrects, total_loss = 0, 0\n","    for batch in val_iter:\n","        x, y = batch.text.to(DEVICE), batch.label.to(DEVICE)\n","        y.data.sub_(1) # 레이블 값을 0과 1로 변환\n","        logit = model(x)\n","        loss = F.cross_entropy(logit, y, reduction='sum')\n","        total_loss += loss.item()\n","        corrects += (logit.max(1)[1].view(y.size()).data == y.data).sum()\n","    size = len(val_iter.dataset)\n","    avg_loss = total_loss / size\n","    avg_accuracy = 100.0 * corrects / size\n","    return avg_loss, avg_accuracy\n","\n","model = RNN(1, 256, vocab_size, 128, n_classes, 0.5).to(DEVICE)\n","optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n","\n","best_val_loss = None\n","for e in range(1, EPOCHS+1):\n","    train(model, optimizer, train_iter)\n","    val_loss, val_accuracy = evaluate(model, val_iter)\n","\n","    print(\"[에폭: %d] 검증 오차:%5.2f | 검증 정확도:%5.2f\" % (e, val_loss, val_accuracy))\n","    \n","    if not best_val_loss or val_loss < best_val_loss:\n","        if not os.path.isdir(\"snapshot\"):\n","            os.makedirs(\"snapshot\")\n","        torch.save(model.state_dict(), './snapshot/txtclassification.pt')\n","        best_val_loss = val_loss\n","\n","model.load_state_dict(torch.load('./snapshot/txtclassification.pt'))\n","test_loss, test_acc = evaluate(model, test_iter)\n","print('테스트 오차: %5.2f | 테스트 정확도: %5.2f' % (test_loss, test_acc))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["다음 기기로 학습합니다: cuda\n","데이터 로딩중...\n","[학습 데이터]: 20000 [검증 데이터]: 5000 [테스트 데이터]: 25000 [단어수]: 46159 [클래스] 2\n","Building Basic RNN model...\n","[에폭: 1] 검증 오차: 0.69 | 검증 정확도:51.44\n","[에폭: 2] 검증 오차: 0.70 | 검증 정확도:50.20\n","[에폭: 3] 검증 오차: 0.70 | 검증 정확도:51.40\n","[에폭: 4] 검증 오차: 0.71 | 검증 정확도:50.70\n","[에폭: 5] 검증 오차: 0.73 | 검증 정확도:50.50\n","[에폭: 6] 검증 오차: 0.74 | 검증 정확도:50.78\n","[에폭: 7] 검증 오차: 0.75 | 검증 정확도:51.82\n","[에폭: 8] 검증 오차: 0.75 | 검증 정확도:51.04\n","[에폭: 9] 검증 오차: 0.74 | 검증 정확도:52.08\n","[에폭: 10] 검증 오차: 0.82 | 검증 정확도:58.84\n","[에폭: 11] 검증 오차: 0.56 | 검증 정확도:73.36\n","[에폭: 12] 검증 오차: 0.50 | 검증 정확도:78.16\n","[에폭: 13] 검증 오차: 0.49 | 검증 정확도:79.92\n","[에폭: 14] 검증 오차: 0.54 | 검증 정확도:79.82\n","[에폭: 15] 검증 오차: 0.54 | 검증 정확도:81.30\n","[에폭: 16] 검증 오차: 0.61 | 검증 정확도:79.98\n","[에폭: 17] 검증 오차: 0.56 | 검증 정확도:82.74\n","[에폭: 18] 검증 오차: 0.57 | 검증 정확도:81.22\n","[에폭: 19] 검증 오차: 0.59 | 검증 정확도:81.42\n","[에폭: 20] 검증 오차: 0.60 | 검증 정확도:81.70\n","테스트 오차:  0.51 | 테스트 정확도: 79.26\n"],"name":"stdout"}]}]}